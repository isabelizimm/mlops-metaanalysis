name,type,description
Aim,version,A super-easy way to record search and compare AI experiments.
aiWARE,ml platform,aiWARE helps MLOps teams evaluate deploy integrate scale & monitor ML models.
ClearML,ml platform,ML/DL development and production suite
Apache Marvin,version,platform for model deployment and versioning that hides all complexity under the hood: data scientists just need to set up the server and write their code in an extended jupyter notebook.
Backprop ,serving and monitoring,Backprop makes it simple to use finetune and deploy state-of-the-art ML models.
Banana,serving,Host your ML inference code on serverless GPUs and integrate it into your app with one line of code.
BentoML,serving and monitoring,BentoML is an open source framework for high performance ML model serving
Bodywork,ml platform,Deploys machine learning projects developed in Python to Kubernetes.
BudgetML,serving,Deploy a ML inference service on a budget in less than 10 lines of code.
CNVRG,ml platform,An end-to-end machine learning platform to build and deploy AI models at scale.
Comet,lifecyle,Track your datasets code changes experimentation history and models.
Cortex,serving and monitoring,Cortex is an open source platform for deploying machine learning models—trained with any framework—as production web services. No DevOps required.
D6tflow,version,A python library that allows for building complex data science workflows on Python.
DAGsHub,ml platform,A platform built on open source tools for data model and pipeline management.
DVC,version,A git fork that allows for version management of models.
Edge Impulse,ml platform,Platform for creating optimizing and deploying AI/ML algorithms for edge devices.
envd,ml platform,Machine learning development environment for data science and AI/ML engineering teams.
Evidently,serving and monitoring,Evidently helps analyze machine learning models during development validation or production monitoring. The tool generates interactive reports from pandas DataFrame.
FGLab,version,Machine learning dashboard designed to make prototyping experiments easier.
Flor,version,Easy to use logger and automatic version controller made for data scientists who write ML code
Flyte,workflow,Easy to create concurrent scalable and maintainable workflows for machine learning.
Gradio,serving,Create customizable UI components around your models.
GraphPipe,serving,Machine learning model deployment made simple.
Hydrosphere,serving,Platform for deploying your Machine Learning to production.
Kale,workflow,Aims at simplifying the Data Science experience of deploying Kubeflow Pipelines workflows.
Kedro,workflow,Library that implements software engineering best-practice for data and ML pipelines.
Keepsake ,version,Version control for machine learning.
KFServing,serving,Kubernetes custom resource definition for serving ML models on arbitrary frameworks.
Knime,ml platform,Create and productionize data science using one easy and intuitive environment.
Kubeflow,ml platform,Making deployments of ML workflows on Kubernetes simple portable and scalable.
Losswise,lifecyle,Makes it easy to track the progress of a machine learning project.
Merlin,serving,A platform for deploying and serving machine learning models.
Metaflow,workflow,Human-friendly lib that helps scientists and engineers build and manage data science projects.
MLflow,version,Open source platform to manage the ML lifecycle including experimentation reproducibility and deployment.
MLReef,ml platform,Open source MLOps platform that helps you collaborate reproduce and share your ML work.
MLRun,workflow,Generic mechanism for data scientists to build run and monitor ML tasks and pipelines.
MLServer,serving and monitoring,An inference server for your machine learning models including support for multiple frameworks multi-model serving and more
mltrace,serving and monitoring,"a lightweight open-source Python tool to get ""bolt-on"" observability in ML pipelines."
MLWatcher,version,MLWatcher is a python agent that records a large variety of time-serie metrics of your running ML classification algorithm. It enables you to monitor in real time.
ModelDB,lifecyle,Open source ML model versioning metadata and experiment management.
Mosec,serving and monitoring,A rust-powered and multi-stage pipelined model server which offers dynamic batching and more. Super easy to implement and deploy as micro-services.
Neptune AI,lifecyle,The most lightweight experiment management tool that fits any workflow.
Opyrator,serving,Turns your ML code into microservices with web API interactive GUI and more.
ormb,version,Docker for Your ML/DL Models Based on OCI Artifacts.
Ploomber,workflow,Write maintainable production-ready pipelines. Develop locally deploy to the cloud.
Polyaxon,version,A platform for reproducible and scalable machine learning and deep learning on kubernetes. - (Video)
PredictionIO,serving,Event collection deployment of algorithms evaluation querying predictive results via APIs.
Prefect,workflow,A workflow management system designed for modern infrastructure.
Redis-AI,serving and monitoring,A Redis module for serving tensors and executing deep learning models. Expect changes in the API and internals.
Replicate,lifecyle,Library that uploads files and metadata (like hyperparameters) to S3 or GCS.
Rune,serving,Provides containers to encapsulate and deploy EdgeML pipelines and applications.
Sacred,lifecyle,A tool to help you configure organize log and reproduce experiments.
Seldon Core,serving and monitoring,Open source platform for deploying and monitoring machine learning models in kubernetes
steppy ,version,Lightweight Python3 library for fast and reproducible machine learning experimentation. Introduces simple interface that enables clean machine learning pipeline design.
Studio.ML,version,Model management framework which minimizes the overhead involved with scheduling running monitoring and managing artifacts of your machine learning experiments.
Tempo,serving and monitoring,Open source SDK that provides a unified interface to multiple MLOps projects that enable data scientists to deploy and productionise machine learning systems.
Transformer-deploy,serving and monitoring,Transformer-deploy is an efficient scalable and enterprise-grade CPU/GPU inference server for Hugging Face transformer models.
Triton Inference Server,serving and monitoring,Triton is a high performance open source serving software to deploy AI models from any framework on GPU & CPU while maximizing utilization.
Valohai,ml platform,Takes you from POC to production while managing the whole model lifecycle.
Vespa,serving,Store search organize and make machine-learned inferences over big data at serving time.